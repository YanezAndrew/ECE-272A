{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a9a5be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4', 'Class']\n",
      "\n",
      "First few rows:\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  28395    610.291       208.178117       173.888747      1.197191   \n",
      "1  28734    638.018       200.524796       182.734419      1.097356   \n",
      "2  29380    624.110       212.826130       175.931143      1.209713   \n",
      "3  30008    645.884       210.557999       182.516516      1.153638   \n",
      "4  30140    620.134       201.847882       190.279279      1.060798   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "1      0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
      "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
      "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
      "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
      "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
      "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
      "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
      "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  \n"
     ]
    }
   ],
   "source": [
    "# Check the actual column names in the dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./autograder/source/drybean.csv')\n",
    "print(\"Column names:\", data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d224a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ae4e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"You are a python coding assistant. \"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35da6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read prompt from the text file\n",
    "with open('hw2_q1_prompt.txt', 'r') as file:\n",
    "    prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8df6bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split, GridSearchCV\n",
      "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import warnings\n",
      "\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Load dataset\n",
      "data = pd.read_csv('/autograder/source/drybean.csv')\n",
      "\n",
      "# Fix column name typos\n",
      "data.rename(columns={'AspectRation': 'AspectRatio', 'roundness': 'Roundness'}, inplace=True)\n",
      "\n",
      "# Define features and target\n",
      "X = data.drop(columns='Class')\n",
      "y = data['Class']\n",
      "\n",
      "# Train/validation/test split\n",
      "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
      "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
      "\n",
      "# Function to log-transform Area\n",
      "def log_area(X):\n",
      "    X = X.copy()\n",
      "    X['Area'] = np.log(X['Area'] + 1e-6)\n",
      "    return X\n",
      "\n",
      "# Preprocessing pipeline\n",
      "numeric_features = ['AspectRatio', 'Eccentricity', 'Roundness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3']\n",
      "\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', Pipeline([\n",
      "            ('log_area', FunctionTransformer(log_area, validate=False)),\n",
      "            ('scaler', StandardScaler())\n",
      "        ]), numeric_features)\n",
      "    ]\n",
      ")\n",
      "\n",
      "# Define models and hyperparameter grids\n",
      "models = {\n",
      "    'DecisionTree': (DecisionTreeClassifier(random_state=42), {'classifier__max_depth': [None, 5, 10, 15]}),\n",
      "    'KNN': (KNeighborsClassifier(), {'classifier__n_neighbors': [3, 5, 7, 9]}),\n",
      "    'LogisticRegression': (LogisticRegression(solver='lbfgs', max_iter=1000, multi_class='multinomial', random_state=42), {'classifier__C': [0.1, 1, 10]})\n",
      "}\n",
      "\n",
      "best_accuracy = 0\n",
      "best_model = None\n",
      "best_params = {}\n",
      "\n",
      "for model_name, (model, params) in models.items():\n",
      "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
      "    grid_search = GridSearchCV(pipeline, params, cv=5)\n",
      "    grid_search.fit(X_train, y_train)\n",
      "    \n",
      "    if grid_search.best_score_ > best_accuracy:\n",
      "        best_accuracy = grid_search.best_score_\n",
      "        best_model = grid_search.best_estimator_\n",
      "        best_params = grid_search.best_params_\n",
      "\n",
      "# Evaluate on train, validation, and test sets\n",
      "train_accuracy = best_model.score(X_train, y_train)\n",
      "valid_accuracy = best_model.score(X_valid, y_valid)\n",
      "test_accuracy = best_model.score(X_test, y_test)\n",
      "\n",
      "# Print accuracies\n",
      "print({'train': train_accuracy, 'valid': valid_accuracy, 'test': test_accuracy})\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "generated_code = call_llm(prompt)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64667297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.9156257653686015, 'valid': 0.9243203526818515, 'test': 0.9151670951156813}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('./autograder/source/drybean.csv')\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=42, stratify=y_train_temp)\n",
    "\n",
    "def log_area(X):\n",
    "    X = X.copy()\n",
    "    X['Area'] = np.log(X['Area'] + 1e-6)\n",
    "    return X\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['AspectRation', 'Eccentricity', 'roundness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3']),\n",
    "        ('log', FunctionTransformer(log_area, validate=False), ['Area'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'DecisionTree': {\n",
    "        'classifier': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__max_depth': [None, 5, 10, 15]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'classifier': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 9]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'classifier': LogisticRegression(solver='lbfgs', max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "        'params': {\n",
    "            'classifier__C': [0.1, 1, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for name, config in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', config['classifier'])\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, config['params'], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    if grid_search.best_score_ > best_accuracy:\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_model = grid_search\n",
    "\n",
    "train_accuracy = best_model.score(X_train, y_train)\n",
    "valid_accuracy = best_model.score(X_valid, y_valid)\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print({'train': train_accuracy, 'valid': valid_accuracy, 'test': test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfaee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.9183198628459466, 'valid': 0.9202792064658339, 'test': 0.9078222548659567}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./autograder/source/drybean.csv')\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "# Stratified train/validation/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Preprocessing function for log transformation\n",
    "def log_area(X):\n",
    "    X = X.copy()\n",
    "    X['Area'] = np.log(X['Area'] + 1e-6)\n",
    "    return X\n",
    "\n",
    "# Define the preprocessing and model pipeline\n",
    "# Note: Column names have typos in the dataset - 'AspectRation' not 'AspectRatio', 'roundness' not 'Roundness'\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['AspectRation', 'Eccentricity', 'roundness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3']),\n",
    "        ('log_area', FunctionTransformer(log_area, validate=False), ['Area'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {'classifier__max_depth': [None, 5, 10, 15]}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'classifier__n_neighbors': [3, 5, 7, 9]}\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42),\n",
    "        'params': {'classifier__C': [0.1, 1, 10]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Model selection using GridSearchCV\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', config['model'])])\n",
    "    grid_search = GridSearchCV(pipe, param_grid=config['params'], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best accuracy from the grid search\n",
    "    if grid_search.best_score_ > best_accuracy:\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on training, validation and test sets\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
    "valid_accuracy = accuracy_score(y_valid, best_model.predict(X_valid))\n",
    "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
    "\n",
    "# Print the accuracies\n",
    "print({'train': train_accuracy, 'valid': valid_accuracy, 'test': test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e3e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 0.9226671565025716, 'valid': 0.9208302718589273, 'test': 0.9081894968784429}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('./autograder/source/drybean.csv')\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=0.5, random_state=42, stratify=y_train_temp)\n",
    "\n",
    "def log_area(X):\n",
    "    X = X.copy()\n",
    "    X['Area'] = np.log(X['Area'] + 1e-6)\n",
    "    return X\n",
    "\n",
    "log_area_transformer = FunctionTransformer(log_area, validate=False)\n",
    "\n",
    "numeric_features = ['AspectRation', 'Eccentricity', 'roundness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'Area']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('log_area', log_area_transformer), ('scaler', StandardScaler())]), numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    'DecisionTree': (DecisionTreeClassifier(random_state=42), {'classifier__max_depth': [None, 5, 10, 15]}),\n",
    "    'KNN': (KNeighborsClassifier(), {'classifier__n_neighbors': [3, 5, 7, 9]}),\n",
    "    'LogisticRegression': (LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42, multi_class='multinomial'), {'classifier__C': [0.1, 1, 10]})\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for model_name, (model, params) in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    if grid_search.best_score_ > best_accuracy:\n",
    "        best_accuracy = grid_search.best_score_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "accuracies = {}\n",
    "for split, X_split, y_split in zip(['train', 'valid', 'test'], [X_train, X_valid, X_test], [y_train, y_valid, y_test]):\n",
    "    accuracies[split] = best_model.score(X_split, y_split)\n",
    "\n",
    "print(accuracies)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
