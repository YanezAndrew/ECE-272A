{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9a5be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4', 'Class']\n",
      "\n",
      "First few rows:\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  28395    610.291       208.178117       173.888747      1.197191   \n",
      "1  28734    638.018       200.524796       182.734419      1.097356   \n",
      "2  29380    624.110       212.826130       175.931143      1.209713   \n",
      "3  30008    645.884       210.557999       182.516516      1.153638   \n",
      "4  30140    620.134       201.847882       190.279279      1.060798   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "1      0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
      "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
      "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
      "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
      "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
      "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
      "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
      "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  \n"
     ]
    }
   ],
   "source": [
    "# Check the actual column names in the dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./autograder/source/drybean.csv')\n",
    "print(\"Column names:\", data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d224a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae4e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"You are a python coding assistant. \"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35da6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read prompt from the text file\n",
    "with open('hw2_q2_prompt.txt', 'r') as file:\n",
    "    prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8df6bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
      "from sklearn.impute import KNNImputer\n",
      "from sklearn.neighbors import KNeighborsRegressor\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "# Load the data\n",
      "data = pd.read_csv('/autograder/source/housing.csv')\n",
      "\n",
      "# Split the data\n",
      "X = data.drop('median_house_value', axis=1)\n",
      "y = data['median_house_value']\n",
      "\n",
      "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.25, random_state=42)\n",
      "\n",
      "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
      "    def __init__(self):\n",
      "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        return self\n",
      "\n",
      "    def transform(self, X):\n",
      "        X_array = X if isinstance(X, np.ndarray) else X.values\n",
      "        distances = np.linalg.norm(X_array[:, :2][:, np.newaxis] - self.anchors, axis=2)\n",
      "        return np.min(distances, axis=1).reshape(-1, 1)\n",
      "\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('anchors', Pipeline(steps=[\n",
      "            ('nearest_anchor', NearestAnchorDistance()),\n",
      "            ('scaler', StandardScaler())\n",
      "        ]), ['latitude', 'longitude']),\n",
      "        ('rooms', Pipeline(steps=[\n",
      "            ('imputer', KNNImputer()),\n",
      "            ('log_transform', FunctionTransformer(np.log1p)),\n",
      "            ('scaler', StandardScaler())\n",
      "        ]), ['total_rooms']),\n",
      "        ('age_income', Pipeline(steps=[\n",
      "            ('imputer', KNNImputer()),\n",
      "            ('scaler', StandardScaler())\n",
      "        ]), ['housing_median_age', 'median_income']),\n",
      "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
      "    ],\n",
      "    remainder='drop'\n",
      ")\n",
      "\n",
      "pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
      "])\n",
      "\n",
      "pipeline.fit(X_train, y_train)\n",
      "\n",
      "y_train_pred = pipeline.predict(X_train)\n",
      "y_valid_pred = pipeline.predict(X_valid)\n",
      "y_test_pred = pipeline.predict(X_test)\n",
      "\n",
      "mae_scores = {\n",
      "    'train': round(mean_absolute_error(y_train, y_train_pred), 2),\n",
      "    'valid': round(mean_absolute_error(y_valid, y_valid_pred), 2),\n",
      "    'test': round(mean_absolute_error(y_test, y_test_pred), 2)\n",
      "}\n",
      "\n",
      "print(mae_scores)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "generated_code = call_llm(prompt)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb93ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        lat_lon = X.values if hasattr(X, 'values') else X\n",
    "        distances = np.linalg.norm(lat_lon[:, np.newaxis, :] - self.anchors, axis=2)\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "\n",
    "# Split data: 60% train, 20% validation, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define preprocessing pipelines for different column groups\n",
    "# For latitude, longitude: custom transformer -> standardization\n",
    "lat_lon_transformer = Pipeline(steps=[\n",
    "    ('nearest_anchor', NearestAnchorDistance()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For total_rooms: KNN imputer -> log transform -> standardization\n",
    "total_rooms_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('log', FunctionTransformer(np.log1p, validate=True)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For housing_median_age, median_income: KNN imputer -> standardization\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For ocean_proximity: one-hot encoding\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine all transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('lat_lon', lat_lon_transformer, ['latitude', 'longitude']),\n",
    "        ('total_rooms', total_rooms_transformer, ['total_rooms']),\n",
    "        ('numeric', numeric_transformer, ['housing_median_age', 'median_income']),\n",
    "        ('cat', categorical_transformer, ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create and train model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, model.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, model.predict(X_test))\n",
    "\n",
    "results = {'train': round(mae_train, 2), 'valid': round(mae_valid, 2), 'test': round(mae_test, 2)}\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3082e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "\n",
    "# Split the data\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        distances = np.sqrt(((X[['latitude', 'longitude']].values[:, np.newaxis] - self.anchors) ** 2).sum(axis=2))\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline([\n",
    "            ('nearest_anchor', NearestAnchorDistance()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['latitude', 'longitude']),\n",
    "        ('rooms', Pipeline([\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('log1p', FunctionTransformer(np.log1p)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['total_rooms']),\n",
    "        ('age_income', Pipeline([\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['housing_median_age', 'median_income']),\n",
    "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pipeline.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, pipeline.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n",
    "\n",
    "mae_results = {\n",
    "    'train': round(mae_train, 2),\n",
    "    'valid': round(mae_valid, 2),\n",
    "    'test': round(mae_test, 2)\n",
    "}\n",
    "\n",
    "print(mae_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5d2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "\n",
    "# Split the data\n",
    "train_val, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train, valid = train_test_split(train_val, test_size=0.25, random_state=42)\n",
    "X_train = train.drop('median_house_value', axis=1)\n",
    "y_train = train['median_house_value']\n",
    "X_valid = valid.drop('median_house_value', axis=1)\n",
    "y_valid = valid['median_house_value']\n",
    "X_test = test.drop('median_house_value', axis=1)\n",
    "y_test = test['median_house_value']\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([(37.38, -122.21), (33.99, -118.50), (32.82, -117.31)])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        lat_lon = X[['latitude', 'longitude']].values\n",
    "        distances = np.linalg.norm(lat_lon[:, None] - self.anchors, axis=2)\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline([\n",
    "            ('nearest_anchor', NearestAnchorDistance()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['latitude', 'longitude']),\n",
    "        \n",
    "        ('rooms', Pipeline([\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('log_transform', FunctionTransformer(np.log1p)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['total_rooms']),\n",
    "        \n",
    "        ('age_income', Pipeline([\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['housing_median_age', 'median_income']),\n",
    "        \n",
    "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pipeline.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, pipeline.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n",
    "\n",
    "results = {\n",
    "    'train': round(mae_train, 2),\n",
    "    'valid': round(mae_valid, 2),\n",
    "    'test': round(mae_test, 2)\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "452c6b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X will be a numpy array when passed from ColumnTransformer\n",
    "        X_array = X if isinstance(X, np.ndarray) else X.values\n",
    "        distances = np.linalg.norm(X_array[:, np.newaxis] - self.anchors, axis=2)\n",
    "        return distances.min(axis=1).reshape(-1, 1)\n",
    "\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline([('nearest_anchor', NearestAnchorDistance()), ('scaler', StandardScaler())]), ['latitude', 'longitude']),\n",
    "        ('total_rooms', Pipeline([('imputer', KNNImputer()), ('log1p', FunctionTransformer(np.log1p)), ('scaler', StandardScaler())]), ['total_rooms']),\n",
    "        ('age_income', Pipeline([('imputer', KNNImputer()), ('scaler', StandardScaler())]), ['housing_median_age', 'median_income']),\n",
    "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pipeline.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, pipeline.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n",
    "\n",
    "mae_results = {\n",
    "    'train': round(mae_train, 2),\n",
    "    'valid': round(mae_valid, 2),\n",
    "    'test': round(mae_test, 2)\n",
    "}\n",
    "\n",
    "print(mae_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a326e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "\n",
    "# Split the data\n",
    "X = data.drop(columns='median_house_value')\n",
    "y = data['median_house_value']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_array = X if isinstance(X, np.ndarray) else X.values\n",
    "        distances = np.linalg.norm(X_array[:, None, :2] - self.anchors[None, :, :], axis=2)\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline([('nearest_anchor', NearestAnchorDistance()), ('scaler', StandardScaler())]), ['latitude', 'longitude']),\n",
    "        ('rooms', Pipeline([('imputer', KNNImputer()), ('log1p', FunctionTransformer(np.log1p)), ('scaler', StandardScaler())]), ['total_rooms']),\n",
    "        ('age_income', Pipeline([('imputer', KNNImputer()), ('scaler', StandardScaler())]), ['housing_median_age', 'median_income']),\n",
    "        ('ocean', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pipeline.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, pipeline.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n",
    "\n",
    "mae_results = {\n",
    "    'train': round(mae_train, 2),\n",
    "    'valid': round(mae_valid, 2),\n",
    "    'test': round(mae_test, 2)\n",
    "}\n",
    "\n",
    "print(mae_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53dc0a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "\n",
    "# Split the data\n",
    "X = data.drop(columns='median_house_value')\n",
    "y = data['median_house_value']\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_array = X if isinstance(X, np.ndarray) else X.values\n",
    "        distances = np.linalg.norm(X_array[:, :2][:, np.newaxis] - self.anchors, axis=2)\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline(steps=[\n",
    "            ('nearest_anchor', NearestAnchorDistance()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['latitude', 'longitude']),\n",
    "        \n",
    "        ('rooms', Pipeline(steps=[\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('log', FunctionTransformer(np.log1p)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['total_rooms']),\n",
    "        \n",
    "        ('age_income', Pipeline(steps=[\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['housing_median_age', 'median_income']),\n",
    "        \n",
    "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pipeline.predict(X_train))\n",
    "mae_valid = mean_absolute_error(y_valid, pipeline.predict(X_valid))\n",
    "mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n",
    "\n",
    "mae_results = {\n",
    "    'train': round(mae_train, 2),\n",
    "    'valid': round(mae_valid, 2),\n",
    "    'test': round(mae_test, 2)\n",
    "}\n",
    "\n",
    "print(mae_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f69cf225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 38028.78, 'valid': 45945.26, 'test': 46600.01}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./autograder/source/housing.csv')\n",
    "\n",
    "# Split the data\n",
    "X = data.drop('median_house_value', axis=1)\n",
    "y = data['median_house_value']\n",
    "\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.25, random_state=42)\n",
    "\n",
    "class NearestAnchorDistance(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.anchors = np.array([[37.38, -122.21], [33.99, -118.50], [32.82, -117.31]])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_array = X if isinstance(X, np.ndarray) else X.values\n",
    "        distances = np.linalg.norm(X_array[:, :2][:, np.newaxis] - self.anchors, axis=2)\n",
    "        return np.min(distances, axis=1).reshape(-1, 1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('anchors', Pipeline(steps=[\n",
    "            ('nearest_anchor', NearestAnchorDistance()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['latitude', 'longitude']),\n",
    "        ('rooms', Pipeline(steps=[\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('log_transform', FunctionTransformer(np.log1p)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['total_rooms']),\n",
    "        ('age_income', Pipeline(steps=[\n",
    "            ('imputer', KNNImputer()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['housing_median_age', 'median_income']),\n",
    "        ('ocean_proximity', OneHotEncoder(handle_unknown='ignore'), ['ocean_proximity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_valid_pred = pipeline.predict(X_valid)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae_scores = {\n",
    "    'train': round(mean_absolute_error(y_train, y_train_pred), 2),\n",
    "    'valid': round(mean_absolute_error(y_valid, y_valid_pred), 2),\n",
    "    'test': round(mean_absolute_error(y_test, y_test_pred), 2)\n",
    "}\n",
    "\n",
    "print(mae_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
